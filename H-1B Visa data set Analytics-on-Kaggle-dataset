H-1B Visa Petitions 2011-2016 From Kaggle
*****************************************
//sed command to remove the double quotes
sed s"/\"//g" sample |sed s'/ //g'

//Moving the dataset to hadoop cluster
hadoop fs -put h-1b_applications.csv .

//Launch the Hive and run the below DDL & DML statements
*******************************************************
//creating the table for dataset
create table h1b (no String,CASE_STATUS String, EMPLOYER_NAME String, 
SOC_NAME String,
JOB_TITLE String,
FULL_TIME_POSITION String,
WAGE String,
YEAR String,
WORK_SITE String,
lon String,
lat String ) 
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
"separatorChar"="," ,
"quoteChar"='"' ,
"escapeChar"="\\"
) 
STORED AS TEXTFILE;

//Loading data to the table
LOAD DATA INPATH "/user/cloudera/datasets/h-1b_applications.csv" OVERWRITE INTO TABLE h1b;

//create a similar table with different delimiter to read data.
create table h1b_tab ROW FORMAT DELIMITED fields terminated by '|' as select * from h1b;


Analytics On the Dataset
************************
//Do Applications for Data Engineer Post incresing over year by year
select YEAR,COUNT(1) AS APPLICATIONS from h1b where trim(JOB_TITLE) ="DATA ENGINEER" 
group by year order by year asc;

//which region of US has more Hard ware engineers
select WORK_SITE,count(1) as NO_OF_PLACE from h1b 
where trim(JOB_TITLE) ="HARDWARE ENGINEER"
group by WORK_SITE order by PLACE DESC

//Which Industry has applied more data scientists Jobs
SELECT SOC_NAME,Count(1) AS NO_OF_DATA_SCIENTISTS
FROM H1B WHERE TRIM(JOB_TITLE)="DATA SCIENTIST"
GROUP BY SOC_NAME ORDER BY NO_OF_DATA_SCIENTISTS desc;

//List the Top 10 Employers on every year beased on max number of applications
SELECT YEAR,EMPLOYER_NAME,Petitions FROM (
SELECT YEAR,EMPLOYER_NAME,Petitions, 
DENSE_RANK() over(partition by YEAR order by Petitions DESC) as RNK from (
SELECT YEAR,EMPLOYER_NAME,Count(1) as Petitions 
FROM H1B 
GROUP BY YEAR,EMPLOYER_NAME 
order by Petitions desc
) A
) A1 
WHERE RNK <=10;

Similar Solutions can get from Spark-Shell or Spark-scala code
**************************************************************
//Launch Spark-shell

spark-shell

//Remove the header of the dataset
val header=sc.textFile("datasets/h1b_tab").first
val h1b_dataset=sc.textFile("datasets/h1b_tab").filter(r=>(r!=header))

//to preview the data
h1b_dataset.take(5).foreach(println)

//Is Number of Petitions with "DATA ENGINEER" JOb Title increasing Over time?
val res1=h1b_dataset.filter(r=>(r.split("\\|")(4).trim =="DATA ENGINEER"))
                    .map(r=>(r.split("\\|")(7).toInt))
                    .map(r=>(r,1))
                    .reduceByKey(_ + _)
                    .map(r=>(r.swap))
                    .sortByKey(false)
                    .map(r=>r._2 + "*" + r._1)

//Which Partof the US has more "HARDWARE ENGINEERING" Jobs?
val res2=h1b_dataset.filter(r=>(r.split("\\|")(4).trim =="HARDWARE ENGINEER"))
                    .map(r=>(r.split("\\|")(8)))
                    .map(r=>(r,1))
                    .reduceByKey(_ + _)
                    .map(r=>(r.swap))
                    .sortByKey(false)
                    .map(r=>r._2 + "*" + r._1)

//Which Industry has the Most Number of data scientists Postions?
val res3=h1b_dataset.filter(r=>(r.split("\\|")(4).trim =="DATA SCIENTIST"))
                    .map(r=>(r.split("\\|")(3)))
                    .map(r=>(r,1))
                    .reduceByKey(_ + _)
                    .map(r=>(r.swap))
                    .sortByKey(false)
                    .map(r=>r._2 + "*" + r._1)

//Top 10 Employers has filled the most petitons in each year?
val res4=h1b_dataset.filter(r=>(!r.split("\\|")(7).isEmpty))
                    .map(r=>(r.split("\\|")(7),r.split("\\|")(2))) 
                    .map(r=>(r,1))
                    .reduceByKey(_ + _)
                    .map(r=>(r.swap))
                    .sortByKey(false)
                    .map(r=>r._2._1 + "|" + r._2._2 + "|" + r._1)


         val final_res4=res4.map(r=>(r.split("\\|")(0),r))
                            .filter(r=>(r._1.trim.length ==4))
                            .sortByKey()
                            .groupByKey()
                            .flatMap(r=>(r._2.toList.sortBy(r=>(-r.split("\\|")(2).toInt)).take(10)))

//Find out top 5 Industries applying for H1B every year
val res5=h1b_dataset.filter(r=>(!r.split("\\|")(7).isEmpty))
                    .filter(r=>(r.split("\\|")(7).trim.length ==4))
                    .map(r=>(r.split("\\|")(7).toInt,r.split("\\|")(3)))
                    .map(r=>(r,1))
                    .reduceByKey(_ + _)
                    .sortBy(r=>(r._1._1,true))
                    .map(r=>(r._1._1+"|"+r._1._2+"|"+r._2))

        val fin_res5=res5.map(r=>(r.split("\\|")(0),r))
                         .groupByKey()
                         .flatMap(r=>(r._2.toList.sortBy(r=>(-r.split("\\|")(2).toInt)).take(5)))
                         .sortBy(r=>(r.split("\\|")(0).toInt))

//Compare employees min,max and avg wages on each Job Tille for every year.
val res6=h1b_dataset.filter(r=>(!r.split("\\|")(7).isEmpty))
                    .filter(r=>(r.split("\\|")(7).trim.length ==4))
                    .filter(r=>(r.split("\\|")(6).trim !="NA"))
                    .map(r=>((r.split("\\|")(7).toInt,r.split("\\|")(4)),r.split("\\|")(6).toFloat))


       val fin_res6=res6.aggregateByKey((0.0, 999999999.0, 0.0, 0))(
                                       (x, y) => (math.max(x._1, y), math.min(x._2, y), x._3 + y, x._4 +1),
                                       (x, y) => (math.max(x._1, y._1), math.min(x._2, y._2), x._3 + y._3, x._4 + y._4))
                         .map(r=>(r._1._1, r._1._2, r._2._1,r._2._2, r._2._3/r._2._4))
                         .map(r=>r._1+"*"+r._2+"*"+r._3+"*"+r._4+"*"+r._5)




//Store all the solutions into textFiles with '*' as delimiter

res1.saveAsTextFile("datasets/h1b-Answers/data-engineers")
res2.saveAsTextFile("datasets/h1b-Answers/hardware-engineers-locations") 
res3.saveAsTextFile("datasets/h1b-Answers/data-Scienciests-Industries")
final_res4.saveAsTextFile("datasets/h1b-Answers/top-employers-applications")
fin_res5.saveAsTextFile("datasets/h1b-Answers/top-Industries-everyyear")
fin_res6.saveAsTextFile("datasets/h1b-Answers/wages-compare-everyyear-jobtitle")
